# 3D Bin Packing Optimization

Repository for the Capstone Project 3D Packing Optimization of the [Fourthbrain Machine Learning Engineer program](https://www.fourthbrain.ai/machine-learning-engineer).

This repository contains an environment compatible with [OpenAI Gym's API](https://github.com/openai/gym) to solve the 
3D bin packing problem with reinforcement learning (RL).


![Alt text](gifs/random_rollout2.gif?raw=true "A random packing agent in the environment")

## Problem definition and assumptions:
The environment consists of a list of 3D boxes of varying sizes and a single container of fixed size. The goal is to pack
as many boxes as possible in the container minimizing the empty volume. We assume that rotation of the boxes is 
not possible.

##  Problem instances: 
The function `boxes_generator` in the file `utils.py` generates instances of the 3D Bin Packing problem using the 
algorithm described in [Ranked Reward: Enabling Self-Play Reinforcement Learning for Combinatorial Optimization](https://arxiv.org/pdf/1807.01672.pdf)
(Algorithm 2, Appendix).

## Documentation
The documentation for this project is located in the `doc` folder, with a complete description of the state and 
action space as well as the rewards to be used for RL training.

## Installation instructions
We recommend that you create a virtual environment with Python 3.8 (for example, using conda environments). 
In your terminal window, activate your environment and clone the repository:
``` 
git clone https://github.com/luisgarciar/3D-bin-packing.git
```

To run the code, you need to install a few dependencies. Go to the cloned directory and install the required packages:
```
cd 3D-bin-packing
pip install -r requirements.txt
```

## Packing engine
The module `packing_engine` (located in `src/packing_engine.py`) implements the `Container` and `Box` objects that are 
used in the Gym environment. To add custom features (for example, to allow rotations), see the documentation of this module.

## Environment
The Gym environment is implemented in the module `src/packing_env.py`.

## Demo notebooks
A demo notebook `demo_ffd` implementing the heuristic-based method 'First Fit Decreasing' is available in the `nb` 
folder.

## Unit tests
The folder `tests` contains unit tests to be run with pytest.

## Update: 22/08/2022
The following updates have been made to the repository:
- Added the `packing_env.py` file with the Gym environment.
- Added unit tests for the Gym environment.
- Updated the documentation with the full description of the state and action space.
- Updated the demo notebooks.

## Update: 13/09/2022
The following updates have been made to the repository:
- Added functionality for saving rollouts of a policy in a .gif file and
- Added a demo notebook for the random policy.
- Updated the requirements.txt file with the required packages.
- Added a demo script for training agents with Maskable PPO. 

## Update: 7/1/2023 
The following updates have been made to the repository:
- Updated the demo notebook for training agents with Maskable PPO in Google colab.
- Fixed issues with the tests.

## ğŸš€ Update: ì¢…í•© ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥ ëŒ€í­ ê°•í™”! (2024ë…„ 12ì›”)
**í™œìš©ë¥ ê³¼ ì•ˆì •ì„± ì§€í‘œê¹Œì§€ í¬í•¨í•œ** ìƒˆë¡œìš´ **ì¢…í•© ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ì„±ëŠ¥ ë¶„ì„** ê¸°ëŠ¥ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!

### âœ¨ ì£¼ìš” ì‹ ê¸°ëŠ¥

#### ğŸ¯ **ì»¨í…Œì´ë„ˆ í™œìš©ë¥  ì‹¤ì‹œê°„ ì¶”ì **
- **ì—í”¼ì†Œë“œë³„ í™œìš©ë¥ **: ê° ì—í”¼ì†Œë“œì—ì„œ ë‹¬ì„±í•œ ì»¨í…Œì´ë„ˆ ê³µê°„ í™œìš©ë¥  ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- **í‰ê°€ í™œìš©ë¥ **: ì£¼ê¸°ì  í‰ê°€ì—ì„œì˜ í™œìš©ë¥  ì„±ëŠ¥ ì¶”ì 
- **ìµœëŒ€ í™œìš©ë¥  ê¸°ë¡**: ì§€ê¸ˆê¹Œì§€ ë‹¬ì„±í•œ ìµœê³  í™œìš©ë¥  ì§€ì† ì¶”ì 
- **ëª©í‘œì„  í‘œì‹œ**: 80% ëª©í‘œ í™œìš©ë¥  ê¸°ì¤€ì„ ìœ¼ë¡œ ì„±ê³¼ ì¸¡ì •

#### âš–ï¸ **í•™ìŠµ ì•ˆì •ì„± ì§€í‘œ ë¶„ì„**
- **ë³´ìƒ ì•ˆì •ì„±**: ìµœê·¼ ì—í”¼ì†Œë“œë“¤ì˜ ë³´ìƒ í‘œì¤€í¸ì°¨ë¡œ í•™ìŠµ ì•ˆì •ì„± ì¸¡ì •
- **í™œìš©ë¥  ì•ˆì •ì„±**: í™œìš©ë¥ ì˜ ë³€ë™ì„±ì„ í†µí•œ ì„±ëŠ¥ ì¼ê´€ì„± í‰ê°€
- **í•™ìŠµ smoothness**: í•™ìŠµ ê³¡ì„ ì˜ ë¶€ë“œëŸ¬ì›€ ì •ë„ (0~1 ë²”ìœ„)

#### ğŸ“Š **6ê°œ ì°¨íŠ¸ ì¢…í•© ëŒ€ì‹œë³´ë“œ**
- **ìƒë‹¨**: ì—í”¼ì†Œë“œë³„ ë³´ìƒ + ì»¨í…Œì´ë„ˆ í™œìš©ë¥  (ì´ë™í‰ê·  ë° ëª©í‘œì„  í¬í•¨)
- **ì¤‘ë‹¨**: í‰ê°€ ì„±ëŠ¥ (ë³´ìƒ & í™œìš©ë¥ ) + ì„±ê³µë¥  (ëª©í‘œì„  í¬í•¨)
- **í•˜ë‹¨**: í•™ìŠµ ì•ˆì •ì„± ì§€í‘œ + ì—í”¼ì†Œë“œ ê¸¸ì´ & ìµœëŒ€ í™œìš©ë¥ 

#### âš¡ **ë” ë¹ˆë²ˆí•œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸**
- **ë¹ ë¥¸ ì—…ë°ì´íŠ¸**: 1000 ìŠ¤í…ë§ˆë‹¤ ì£¼ìš” ì°¨íŠ¸ ì—…ë°ì´íŠ¸
- **ì „ì²´ ì—…ë°ì´íŠ¸**: ê¸°ì¡´ ì£¼ê¸°ë¡œ ëª¨ë“  ì°¨íŠ¸ ì¢…í•© ì—…ë°ì´íŠ¸
- **ì‹¤ì‹œê°„ ì½˜ì†” ì¶œë ¥**: í™œìš©ë¥ ê³¼ ì•ˆì •ì„± ì •ë³´ í¬í•¨

### ğŸ› ï¸ ê°„ë‹¨í•œ ì‚¬ìš©ë²•
```bash
# ì¢…í•© ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ê³¼ í•¨ê»˜ í•™ìŠµ ì‹œì‘
python -m src.train_maskable_ppo --timesteps 100000

# ë” ìì£¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
python -m src.train_maskable_ppo --timesteps 50000 --eval-freq 5000

# ì¢…í•© ë¶„ì„ (í™œìš©ë¥  & ì•ˆì •ì„± í¬í•¨)
python -m src.train_maskable_ppo --analyze-only results/comprehensive_training_stats_YYYYMMDD_HHMMSS.npy

# KAMP ì„œë²„ ìë™ ì‹¤í–‰ (ì¢…í•© ëª¨ë‹ˆí„°ë§ í¬í•¨)
./kamp_auto_run.sh master
```

### ğŸ“ˆ ì‹¤ì‹œê°„ ì¶œë ¥ ì˜ˆì‹œ
```
ìŠ¤í…: 25,000 | ì—í”¼ì†Œë“œ: 156 | ìµœê·¼ 10 ì—í”¼ì†Œë“œ í‰ê·  ë³´ìƒ: 0.642 | í‰ê·  í™œìš©ë¥ : 64.2% | ìµœëŒ€ í™œìš©ë¥ : 78.5% | ê²½ê³¼ ì‹œê°„: 180.5ì´ˆ

í‰ê°€ ìˆ˜í–‰ ì¤‘... (ìŠ¤í…: 25,000)
í‰ê°€ ì™„ë£Œ: í‰ê·  ë³´ìƒ 0.685, í‰ê·  í™œìš©ë¥  68.5%, ì„±ê³µë¥  80.0%
```

### ğŸ“ ìë™ ìƒì„± íŒŒì¼
- `comprehensive_training_progress_*.png`: 6ê°œ ì°¨íŠ¸ ì¢…í•© ëŒ€ì‹œë³´ë“œ
- `comprehensive_training_stats_*.npy`: í™œìš©ë¥ +ì•ˆì •ì„± í¬í•¨ ì¢…í•© í†µê³„
- `comprehensive_summary_*.txt`: í•œê¸€ ì„±ê³¼ ìš”ì•½ ë³´ê³ ì„œ (ë“±ê¸‰ í‰ê°€ í¬í•¨)

### ğŸ† ìë™ ë“±ê¸‰ í‰ê°€ ì‹œìŠ¤í…œ
- **í™œìš©ë¥ **: ğŸ¥‡ ìš°ìˆ˜(80%+) / ğŸ¥ˆ ì–‘í˜¸(60-80%) / ğŸ¥‰ ê°œì„ í•„ìš”(60%-)
- **ì„±ê³µë¥ **: ğŸ¥‡ ìš°ìˆ˜(80%+) / ğŸ¥ˆ ì–‘í˜¸(50-80%) / ğŸ¥‰ ê°œì„ í•„ìš”(50%-)
- **í•™ìŠµ ì•ˆì •ì„±**: ğŸ¥‡ ë§¤ìš°ì•ˆì •ì (0.7+) / ğŸ¥ˆ ì•ˆì •ì (0.5-0.7) / ğŸ¥‰ ë¶ˆì•ˆì •(0.5-)

ğŸ“– **ìì„¸í•œ ì‚¬ìš©ë²•**: [`REALTIME_MONITORING_GUIDE.md`](REALTIME_MONITORING_GUIDE.md) ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.
