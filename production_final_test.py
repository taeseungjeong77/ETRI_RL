#!/usr/bin/env python3
"""
ğŸ† í”„ë¡œë•ì…˜ ìµœì  ì„¤ì • ìµœì¢… ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
Phase 4ì—ì„œ ê²€ì¦ëœ ìµœê³  ì„±ëŠ¥ ì„¤ì • (20.591ì )ìœ¼ë¡œ ìµœì¢… í…ŒìŠ¤íŠ¸
"""

import os
import sys
import json
import time
import numpy as np
from datetime import datetime
import warnings
import io

# í™˜ê²½ ì„¤ì •
os.environ['CUDA_VISIBLE_DEVICES'] = ''
os.environ['MPLBACKEND'] = 'Agg'
warnings.filterwarnings("ignore")
sys.path.append('src')

# ğŸ† ê²€ì¦ëœ ìµœê³  ì„±ëŠ¥ ì„¤ì • (Phase 4 ê²°ê³¼)
PRODUCTION_OPTIMAL = {
    "learning_rate": 0.00013,
    "n_steps": 768,
    "batch_size": 96,
    "n_epochs": 5,
    "clip_range": 0.18,
    "ent_coef": 0.008,
    "vf_coef": 0.5,
    "gae_lambda": 0.96,
    "net_arch": {"pi": [256, 128, 64], "vf": [256, 128, 64]}
}

def create_production_env(container_size=[10, 10, 10], num_boxes=12, seed=42):
    """í”„ë¡œë•ì…˜ í™˜ê²½ ìƒì„±"""
    try:
        from train_maskable_ppo import make_env
        
        env = make_env(
            container_size=container_size,
            num_boxes=num_boxes,
            num_visible_boxes=3,
            seed=seed,
            render_mode=None,
            random_boxes=False,
            only_terminal_reward=False,
            improved_reward_shaping=True,
        )()
        
        print(f"âœ… í”„ë¡œë•ì…˜ í™˜ê²½ ìƒì„±: ì»¨í…Œì´ë„ˆ{container_size}, ë°•ìŠ¤{num_boxes}ê°œ")
        return env
        
    except Exception as e:
        print(f"âŒ í™˜ê²½ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def train_production_model(env, timesteps=50000):
    """í”„ë¡œë•ì…˜ ìµœì  ì„¤ì •ìœ¼ë¡œ ëª¨ë¸ í•™ìŠµ"""
    try:
        import torch
        import torch.nn as nn
        from sb3_contrib import MaskablePPO
        
        print(f"ğŸš€ í”„ë¡œë•ì…˜ í•™ìŠµ ì‹œì‘: {timesteps:,} ìŠ¤í…")
        print(f"ğŸ“Š ìµœì  ì„¤ì •: LR={PRODUCTION_OPTIMAL['learning_rate']:.2e}, "
              f"Steps={PRODUCTION_OPTIMAL['n_steps']}, "
              f"Batch={PRODUCTION_OPTIMAL['batch_size']}")
        
        start_time = time.time()
        
        # ìµœì  ì„¤ì •ìœ¼ë¡œ ëª¨ë¸ ìƒì„±
        model = MaskablePPO(
            "MultiInputPolicy",
            env,
            learning_rate=PRODUCTION_OPTIMAL['learning_rate'],
            n_steps=PRODUCTION_OPTIMAL['n_steps'],
            batch_size=PRODUCTION_OPTIMAL['batch_size'],
            n_epochs=PRODUCTION_OPTIMAL['n_epochs'],
            gamma=0.99,
            gae_lambda=PRODUCTION_OPTIMAL['gae_lambda'],
            clip_range=PRODUCTION_OPTIMAL['clip_range'],
            ent_coef=PRODUCTION_OPTIMAL['ent_coef'],
            vf_coef=PRODUCTION_OPTIMAL['vf_coef'],
            max_grad_norm=0.5,
            verbose=1,
            seed=42,
            policy_kwargs=dict(
                net_arch=PRODUCTION_OPTIMAL['net_arch'],
                activation_fn=nn.ReLU,
                share_features_extractor=True,
            )
        )
        
        # í•™ìŠµ ì‹¤í–‰
        model.learn(total_timesteps=timesteps, progress_bar=True)
        
        duration = time.time() - start_time
        print(f"â±ï¸ í•™ìŠµ ì™„ë£Œ: {duration/60:.1f}ë¶„")
        
        return model, duration
        
    except Exception as e:
        print(f"âŒ í•™ìŠµ ì‹¤íŒ¨: {e}")
        return None, 0

def evaluate_production_model(model, container_size=[10, 10, 10], num_boxes=12, n_episodes=50):
    """ê°•í™”ëœ í”„ë¡œë•ì…˜ í‰ê°€ (ë” ë§ì€ ì—í”¼ì†Œë“œ)"""
    print(f"ğŸ” í”„ë¡œë•ì…˜ í‰ê°€ ì‹œì‘: {n_episodes} ì—í”¼ì†Œë“œ")
    
    all_rewards = []
    all_utilizations = []
    placement_counts = []
    success_count = 0
    
    for ep in range(n_episodes):
        seed = 200 + ep * 3  # ë‹¤ì–‘í•œ ì‹œë“œ
        eval_env = create_production_env(container_size, num_boxes, seed)
        
        if eval_env is None:
            continue
        
        obs, _ = eval_env.reset(seed=seed)
        episode_reward = 0.0
        
        for step in range(50):  # ìµœëŒ€ 50ìŠ¤í…
            try:
                action, _ = model.predict(obs, deterministic=False)
                obs, reward, terminated, truncated, info = eval_env.step(action)
                episode_reward += reward
                
                if terminated or truncated:
                    break
                    
            except Exception as e:
                break
        
        # ì„±ê³¼ ê³„ì‚°
        utilization = 0.0
        placed_boxes = 0
        try:
            if hasattr(eval_env.unwrapped, 'container'):
                placed_volume = sum(box.volume for box in eval_env.unwrapped.container.boxes 
                                  if box.position is not None)
                container_volume = eval_env.unwrapped.container.volume
                utilization = placed_volume / container_volume if container_volume > 0 else 0.0
                placed_boxes = sum(1 for box in eval_env.unwrapped.container.boxes 
                                 if box.position is not None)
        except:
            pass
        
        # ì„±ê³µ ê¸°ì¤€: í™œìš©ë¥  25% ì´ìƒ ë˜ëŠ” ë°•ìŠ¤ 50% ì´ìƒ
        if utilization >= 0.25 or placed_boxes >= num_boxes * 0.5:
            success_count += 1
        
        all_rewards.append(episode_reward)
        all_utilizations.append(utilization)
        placement_counts.append(placed_boxes)
        
        if ep < 10 or ep % 10 == 0:
            print(f"   ì—í”¼ì†Œë“œ {ep+1}: ë³´ìƒ={episode_reward:.3f}, "
                  f"í™œìš©ë¥ ={utilization:.1%}, ë°•ìŠ¤={placed_boxes}ê°œ")
        
        eval_env.close()
    
    if not all_rewards:
        return None
    
    results = {
        'mean_reward': np.mean(all_rewards),
        'std_reward': np.std(all_rewards),
        'mean_utilization': np.mean(all_utilizations),
        'std_utilization': np.std(all_utilizations),
        'mean_placement': np.mean(placement_counts),
        'max_placement': max(placement_counts),
        'success_rate': success_count / len(all_rewards),
        'combined_score': np.mean(all_rewards) * 0.3 + np.mean(all_utilizations) * 100 * 0.7,
        'episodes': len(all_rewards),
        'all_rewards': all_rewards,
        'all_utilizations': all_utilizations
    }
    
    return results

def _render_env_frame_3d(env, step_num=0, fig_size_px=(1200, 1200)):
    """matplotlibì„ ì‚¬ìš©í•´ í˜„ì¬ í™˜ê²½ ìƒíƒœë¥¼ 1200x1200 PNG ì´ë¯¸ì§€ë¡œ ë Œë”ë§ í›„ PIL Image ë°˜í™˜"""
    try:
        import matplotlib
        matplotlib.use('Agg')
        import matplotlib.pyplot as plt
        from mpl_toolkits.mplot3d.art3d import Poly3DCollection
        from PIL import Image

        # ì»¨í…Œì´ë„ˆ í¬ê¸°
        container_size = getattr(env.unwrapped, 'container').size

        # 1200x1200 ë³´ì¥: inches * dpi = pixels
        target_w, target_h = fig_size_px
        dpi = 100
        fig_w_in, fig_h_in = target_w / dpi, target_h / dpi

        fig = plt.figure(figsize=(fig_w_in, fig_h_in), dpi=dpi)
        ax = fig.add_subplot(111, projection='3d')

        # ì»¨í…Œì´ë„ˆ ëª¨ì„œë¦¬ì™€ ì—ì§€ ê·¸ë¦¬ê¸°
        corners = [
            [0, 0, 0], [container_size[0], 0, 0],
            [container_size[0], container_size[1], 0], [0, container_size[1], 0],
            [0, 0, container_size[2]], [container_size[0], 0, container_size[2]],
            [container_size[0], container_size[1], container_size[2]], [0, container_size[1], container_size[2]]
        ]
        for cx, cy, cz in corners:
            ax.scatter(cx, cy, cz, color='red', s=20, alpha=0.8)

        edges = [
            ([0, container_size[0]], [0, 0], [0, 0]),
            ([container_size[0], container_size[0]], [0, container_size[1]], [0, 0]),
            ([container_size[0], 0], [container_size[1], container_size[1]], [0, 0]),
            ([0, 0], [container_size[1], 0], [0, 0]),
            ([0, container_size[0]], [0, 0], [container_size[2], container_size[2]]),
            ([container_size[0], container_size[0]], [0, container_size[1]], [container_size[2], container_size[2]]),
            ([container_size[0], 0], [container_size[1], container_size[1]], [container_size[2], container_size[2]]),
            ([0, 0], [container_size[1], 0], [container_size[2], container_size[2]]),
            ([0, 0], [0, 0], [0, container_size[2]]),
            ([container_size[0], container_size[0]], [0, 0], [0, container_size[2]]),
            ([container_size[0], container_size[0]], [container_size[1], container_size[1]], [0, container_size[2]]),
            ([0, 0], [container_size[1], container_size[1]], [0, container_size[2]])
        ]
        for ex, ey, ez in edges:
            ax.plot(ex, ey, ez, 'r-', alpha=0.35, linewidth=1)

        # ë°°ì¹˜ëœ ë°•ìŠ¤ ê·¸ë¦¬ê¸° (env.unwrapped.packed_boxes ì‚¬ìš©)
        packed_boxes = getattr(env.unwrapped, 'packed_boxes', [])
        if packed_boxes:
            colors = plt.cm.Set3(np.linspace(0, 1, len(packed_boxes)))
            for idx, box in enumerate(packed_boxes):
                x, y, z = box.position
                dx, dy, dz = box.size
                vertices = [
                    [x, y, z], [x+dx, y, z], [x+dx, y+dy, z], [x, y+dy, z],
                    [x, y, z+dz], [x+dx, y, z+dz], [x+dx, y+dy, z+dz], [x, y+dy, z+dz]
                ]
                faces = [
                    [vertices[0], vertices[1], vertices[2], vertices[3]],
                    [vertices[4], vertices[5], vertices[6], vertices[7]],
                    [vertices[0], vertices[1], vertices[5], vertices[4]],
                    [vertices[2], vertices[3], vertices[7], vertices[6]],
                    [vertices[0], vertices[3], vertices[7], vertices[4]],
                    [vertices[1], vertices[2], vertices[6], vertices[5]]
                ]
                pc = Poly3DCollection(faces, facecolor=colors[idx], edgecolor='black', alpha=0.8, linewidth=0.5)
                ax.add_collection3d(pc)

        ax.set_xlabel('X (Depth)')
        ax.set_ylabel('Y (Length)')
        ax.set_zlabel('Z (Height)')
        ax.set_xlim(0, container_size[0])
        ax.set_ylim(0, container_size[1])
        ax.set_zlim(0, container_size[2])
        ax.set_title(f'3D Bin Packing - Step {step_num}\n'
                     f'Packed: {len(packed_boxes)}  Container: {container_size}', fontsize=10)
        ax.grid(True, alpha=0.3)
        ax.view_init(elev=25, azim=45)
        plt.tight_layout()

        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=dpi, bbox_inches='tight', facecolor='white')
        buf.seek(0)
        img = Image.open(buf)
        plt.close(fig)
        return img
    except Exception:
        try:
            from PIL import Image
            return Image.new('RGB', (1200, 1200), color='white')
        except Exception:
            return None

def save_gif_like_train15(frames, out_path):
    """train_15_boxes.gif í˜•ì‹ê³¼ ë™ì¼í•˜ê²Œ ì €ì¥ (1200x1200, 11í”„ë ˆì„, 300ms/ë§ˆì§€ë§‰ 2100ms, loop=10)"""
    from PIL import Image

    if not frames:
        return False

    # í”„ë ˆì„ ìˆ˜ë¥¼ 11ê°œë¡œ ë§ì¶¤: ë¶€ì¡±í•˜ë©´ ë§ˆì§€ë§‰ í”„ë ˆì„ ë°˜ë³µ, ë§ìœ¼ë©´ ì˜ë¼ëƒ„
    target_frames = 11
    if len(frames) < target_frames:
        frames = frames + [frames[-1]] * (target_frames - len(frames))
    elif len(frames) > target_frames:
        frames = frames[:target_frames]

    # í¬ê¸° 1200x1200ìœ¼ë¡œ ê°•ì œ
    resized = [f.resize((1200, 1200)) for f in frames]

    # durations: ì• 10í”„ë ˆì„ 300ms, ë§ˆì§€ë§‰ 2100ms
    durations = [300] * (target_frames - 1) + [2100]

    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    try:
        resized[0].save(
            out_path,
            format='GIF',
            append_images=resized[1:],
            save_all=True,
            duration=durations,
            loop=10,  # train_15_boxes.gifì™€ ë™ì¼
            optimize=True
        )
        return True
    except Exception:
        return False

def generate_production_demo_gif(model, container_size=[10,10,10], num_boxes=12, max_steps=80, out_name='production_final_demo.gif'):
    """ì—¬ëŸ¬ ì‹œë„ ì¤‘ ìµœë‹¤ ë°°ì¹˜ ê²°ê³¼ë¥¼ ì‚¬ìš©í•´ train_15_boxes.gif í¬ë§·ìœ¼ë¡œ GIF ìƒì„±"""
    try:
        from sb3_contrib.common.maskable.utils import get_action_masks
    except Exception:
        get_action_masks = None

    seeds = [777, 778, 779, 880, 881]  # ë‹¤ì¤‘ ì‹œë„
    best = {"frames": None, "placed": -1}

    for seed in seeds:
        env = create_production_env(container_size, num_boxes, seed=seed)
        if env is None:
            continue

        try:
            obs, _ = env.reset(seed=seed)
            frames = []
            frames.append(_render_env_frame_3d(env, step_num=0))

            done = False
            truncated = False
            step = 0
            last_packed = len(getattr(env.unwrapped, "packed_boxes", []))
            stagnation = 0   # ë°°ì¹˜ ì •ì²´ ì¹´ìš´í„°

            while not (done or truncated) and step < max_steps:
                try:
                    # 1) ê¸°ë³¸: ëª¨ë¸ ì˜ˆì¸¡ (ê²°ì •ë¡ /ë¹„ê²°ì •ë¡  í˜¼ìš©ìœ¼ë¡œ íƒí—˜ ìœ ë„)
                    use_deterministic = (step % 3 != 0)
                    action = None
                    masks = None
                    if get_action_masks is not None:
                        masks = get_action_masks(env)
                        try:
                            action, _ = model.predict(obs, action_masks=masks, deterministic=use_deterministic)
                        except Exception:
                            action = None
                    else:
                        try:
                            action, _ = model.predict(obs, deterministic=use_deterministic)
                        except Exception:
                            action = None

                    # 2) í´ë°±: ìœ íš¨ ì•¡ì…˜ ì¤‘ í•˜ë‚˜ ì„ íƒ(ë¬´ì‘ìœ„). ì—†ìœ¼ë©´ ì¢…ë£Œ
                    if action is None and masks is not None:
                        valid_idx = np.flatnonzero(masks)
                        if valid_idx.size > 0:
                            action = int(np.random.choice(valid_idx))
                        else:
                            break

                    # ê·¸ë˜ë„ ì—†ìœ¼ë©´ ì¢…ë£Œ
                    if action is None:
                        break

                    # ìŠ¤í… ì‹¤í–‰
                    obs, reward, done, truncated, info = env.step(action)
                    step += 1

                    # ë°°ì¹˜ ì´ë²¤íŠ¸ ê¸°ë°˜ ìº¡ì²˜
                    current_packed = len(getattr(env.unwrapped, "packed_boxes", []))
                    if current_packed > last_packed:
                        frames.append(_render_env_frame_3d(env, step_num=step))
                        last_packed = current_packed
                        stagnation = 0
                    else:
                        stagnation += 1

                    # ì •ì²´ í•´ì†Œ: ì¼ì • ìŠ¤í… ë°°ì¹˜ ì‹¤íŒ¨ ì‹œ ê°•ì œ íƒí—˜(ë§ˆìŠ¤í¬ì—ì„œ ëœë¤ ìƒ˜í”Œ)
                    if stagnation >= 8 and masks is not None:
                        valid_idx = np.flatnonzero(masks)
                        if valid_idx.size > 0:
                            fallback_action = int(np.random.choice(valid_idx))
                            obs, reward, done, truncated, info = env.step(fallback_action)
                            step += 1
                            current_packed2 = len(getattr(env.unwrapped, "packed_boxes", []))
                            if current_packed2 > last_packed:
                                frames.append(_render_env_frame_3d(env, step_num=step))
                                last_packed = current_packed2
                                stagnation = 0
                            else:
                                # ì—¬ì „íˆ ì •ì²´ë©´ ì†Œí­ ë¦¬ì…‹(ë§ˆì´ê·¸ë ˆì´ì…˜ ë°©ì§€)
                                stagnation = max(0, stagnation - 4)

                except Exception:
                    break

            # ìµœë‹¤ ë°°ì¹˜ ì‹œë„ ì„ íƒ
            placed_count = last_packed
            if placed_count > best["placed"] and frames:
                best["placed"] = placed_count
                best["frames"] = frames

        finally:
            env.close()

    # ìµœì¢… ì €ì¥
    if best["frames"]:
        out_path = os.path.join("gifs", out_name)
        ok = save_gif_like_train15(best["frames"], out_path)
        if ok:
            print(f"ğŸ¬ ë°ëª¨ GIF ìƒì„± ì™„ë£Œ: {out_path} (ìµœë‹¤ ë°°ì¹˜: {best['placed']}ê°œ)")
        else:
            print("âš ï¸ ë°ëª¨ GIF ìƒì„± ì‹¤íŒ¨")
        return ok
    else:
        print("âš ï¸ ìœ íš¨í•œ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤.")
        return False

def production_final_test(timesteps=50000, eval_episodes=50):
    """í”„ë¡œë•ì…˜ ìµœì¢… í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸ† í”„ë¡œë•ì…˜ ìµœì  ì„¤ì • ìµœì¢… ê²€ì¦ ì‹œì‘")
    print(f"ğŸ“Š ëª©í‘œ: 20.591ì  ì¬í˜„ ë° ì•ˆì •ì„± ê²€ì¦")
    print("="*60)
    
    # í™˜ê²½ ìƒì„±
    container_size = [10, 10, 10]
    num_boxes = 12
    
    env = create_production_env(container_size, num_boxes, 42)
    if env is None:
        return False
    
    # ëª¨ë¸ í•™ìŠµ
    print(f"\nğŸ“ 1ë‹¨ê³„: í”„ë¡œë•ì…˜ ëª¨ë¸ í•™ìŠµ ({timesteps:,} ìŠ¤í…)")
    model, train_time = train_production_model(env, timesteps)
    
    if model is None:
        env.close()
        return False
    
    # ëª¨ë¸ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_path = f"models/production_optimal_{timestamp}"
    os.makedirs('models', exist_ok=True)
    model.save(model_path)
    print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥: {model_path}")
    
    # ê°•í™”ëœ í‰ê°€
    print(f"\nğŸ“Š 2ë‹¨ê³„: ê°•í™”ëœ í‰ê°€ ({eval_episodes} ì—í”¼ì†Œë“œ)")
    results = evaluate_production_model(model, container_size, num_boxes, eval_episodes)
    
    env.close()
    
    if results is None:
        return False
    
    # ê²°ê³¼ ë¶„ì„ ë° ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ† í”„ë¡œë•ì…˜ ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼")
    print("="*60)
    print(f"ğŸ“Š ì¢…í•© ì ìˆ˜: {results['combined_score']:.3f}")
    print(f"ğŸ¯ ëª©í‘œ ëŒ€ë¹„: {(results['combined_score']/20.591*100):.1f}% (ëª©í‘œ: 20.591)")
    print(f"ğŸ’° í‰ê·  ë³´ìƒ: {results['mean_reward']:.3f} Â± {results['std_reward']:.3f}")
    print(f"ğŸ“¦ í‰ê·  í™œìš©ë¥ : {results['mean_utilization']:.1%} Â± {results['std_utilization']:.1%}")
    print(f"ğŸ² í‰ê·  ë°°ì¹˜: {results['mean_placement']:.1f}ê°œ (ìµœëŒ€: {results['max_placement']}ê°œ)")
    print(f"âœ… ì„±ê³µë¥ : {results['success_rate']:.1%}")
    print(f"â±ï¸ í•™ìŠµ ì‹œê°„: {train_time/60:.1f}ë¶„")
    
    # ì„±ëŠ¥ íŒì •
    if results['combined_score'] >= 20.0:
        print(f"ğŸ‰ ìš°ìˆ˜! ëª©í‘œ ì„±ëŠ¥ ë‹¬ì„± ë˜ëŠ” ê·¼ì ‘")
    elif results['combined_score'] >= 18.57:
        print(f"âœ… ì„±ê³µ! Phase 3 ëª©í‘œ ë‹¬ì„±")
    else:
        print(f"ğŸ“ˆ ê°œì„  í•„ìš”: ì¶”ê°€ íŠœë‹ ê¶Œì¥")
    
    # ìƒì„¸ ê²°ê³¼ ì €ì¥
    final_results = {
        'timestamp': timestamp,
        'test_type': 'production_final',
        'params': PRODUCTION_OPTIMAL,
        'config': {
            'container_size': container_size,
            'num_boxes': num_boxes,
            'timesteps': timesteps,
            'eval_episodes': eval_episodes
        },
        'performance': results,
        'training_time_minutes': train_time/60,
        'model_path': model_path,
        'target_score': 20.591,
        'achievement_rate': results['combined_score']/20.591*100
    }
    
    results_file = f"results/production_final_{timestamp}.json"
    with open(results_file, 'w') as f:
        json.dump(final_results, f, indent=2, default=str)
    
    print(f"\nğŸ’¾ ìƒì„¸ ê²°ê³¼ ì €ì¥: {results_file}")
    
    # === 3ë‹¨ê³„: train_15_boxes.gifì™€ ë™ì¼ í˜•ì‹ì˜ ë°ëª¨ GIF ìƒì„± ===
    try:
        demo_ok = generate_production_demo_gif(
            model,
            container_size=container_size,
            num_boxes=num_boxes,
            max_steps=80,  # 10 -> 80ìœ¼ë¡œ ì¦ê°€
            out_name='production_final_demo.gif'
        )
        if demo_ok:
            # ê²€ì¦ ì¶œë ¥: í”„ë ˆì„ ìˆ˜/loop/duration í™•ì¸
            try:
                from PIL import Image
                img = Image.open('gifs/production_final_demo.gif')
                print(f"ğŸ–¼ï¸ GIF ê²€ì¦: size={img.size}, frames={getattr(img,'n_frames',1)}, loop={img.info.get('loop')}")
            except Exception:
                pass
    except Exception as _:
        print("âš ï¸ ë°ëª¨ GIF ìƒì„± ì¤‘ ì˜ˆì™¸ ë°œìƒ (ë¬´ì‹œí•˜ê³  ì§„í–‰)")
    
    return results['combined_score'] >= 18.57

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='í”„ë¡œë•ì…˜ ìµœì  ì„¤ì • ìµœì¢… í…ŒìŠ¤íŠ¸')
    parser.add_argument('--timesteps', type=int, default=50000, help='í•™ìŠµ ìŠ¤í… ìˆ˜')
    parser.add_argument('--episodes', type=int, default=50, help='í‰ê°€ ì—í”¼ì†Œë“œ ìˆ˜')
    parser.add_argument('--quick', action='store_true', help='ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (25000 ìŠ¤í…)')
    
    args = parser.parse_args()
    
    if args.quick:
        timesteps = 25000
        episodes = 30
        print("âš¡ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
    else:
        timesteps = args.timesteps
        episodes = args.episodes
        print("ğŸ† ì™„ì „ í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
    
    print(f"ğŸš€ ì„¤ì •: {timesteps:,} ìŠ¤í…, {episodes} ì—í”¼ì†Œë“œ")
    
    start_time = time.time()
    success = production_final_test(timesteps, episodes)
    total_time = time.time() - start_time
    
    print(f"\nâ±ï¸ ì´ ì†Œìš” ì‹œê°„: {total_time/60:.1f}ë¶„")
    
    if success:
        print("ğŸ‰ í”„ë¡œë•ì…˜ ìµœì¢… í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
    else:
        print("ğŸ“ˆ ì„±ëŠ¥ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 